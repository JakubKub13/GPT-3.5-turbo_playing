import openai
from dotenv import load_dotenv
import os

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.Model.list()

model_name = "gpt-3.5-turbo"

# Define a function to handle user input and generate a response
def generate_response(prompt):
    response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",

    messages=[
        # The system message helps set the behavior of the assistant. In the example above, the assistant was instructed with â€œYou are a helpful assistant
        {"role": "system", "content": "You are a law assistant."},
        # The user messages help instruct the assistant. They can be generated by the end users of an application, or set by a developer as an instruction.
        {"role": "user", "content": "What type of companies can I set?"},
        # The assistant messages help store prior responses. They can also be written by a developer to help give examples of desired behavior
        {"role": "assistant", "content": "llc, corporation, partnership, etc."},
        {"role": "user", "content": prompt}
        ]    
    )
    return response["choices"][0]["message"]["content"]

# Get user input and generate a response
while True:
    prompt = input("Enter your question: ")
    if prompt.lower() == "quit":
        break
    answer = generate_response(prompt)
    print(answer)
